# ============================================
# AI Provider Configuration
# ============================================
# Switch provider: gemini | openai | anthropic | ollama
AI_PROVIDER=ollama

# Ollama (local) — only needed when AI_PROVIDER=ollama
# Router model: classification only, no tool support needed (gemma3 is fine)
OLLAMA_ROUTER_MODEL=gemma3:4b
# Agent model: MUST support tool calling (qwen3, glm-4.7-flash, etc.)
OLLAMA_AGENT_MODEL=qwen3:4b
AI_BASE_URL=http://localhost:11434
AI_API_KEY=ollama_local_key_placeholder

# Cloud provider keys — only the active provider's key is required
GOOGLE_GENERATIVE_AI_API_KEY=
OPENAI_API_KEY=
ANTHROPIC_API_KEY=

# ============================================
# Database
# ============================================
DATABASE_URL=postgres://user:password@localhost:5432/support_system

# ============================================
# JWT
# ============================================
JWT_ACCESS_SECRET=change_me_access
JWT_REFRESH_SECRET=change_me_refresh
JWT_ACCESS_EXPIRY=30m
JWT_REFRESH_EXPIRY=7d

# ============================================
# Server
# ============================================
PORT=3000
NODE_ENV=development

# ============================================
# Rate Limiting
# ============================================
RATE_LIMIT_WINDOW_MS=60000
RATE_LIMIT_MAX_REQUESTS=20
